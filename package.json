{
  "name": "semantic-chunking",
  "version": "1.3.0",
  "description": "Semantically create chunks from large texts. Useful for workflows involving large language models (LLMs).",
  "repository": {
    "type": "git",
    "url": "https://github.com/jparkerweb/semantic-chunking.git"
  },
  "main": "chunkit.js",
  "type": "module",
  "keywords": [
    "semantic",
    "chunking",
    "sentence",
    "transformers",
    "transformers.js",
    "emmbeddings",
    "onnx",
    "xenova",
    "nlp"
  ],
  "author": "jparkerweb@gmail.com",
  "license": "ISC",
  "scripts": {
    "clean-models": "find ./models -type f ! -name '*.url' -delete",
    "clean-models-win": "powershell -Command \"Get-ChildItem -Path ./models -Recurse | Where-Object { !$_.PSIsContainer -and $_.Extension -ne '.url' } | Remove-Item\"",
    "download-models": "node ./tools/download-models.js"
  },
  "dependencies": {
    "@stdlib/nlp-sentencize": "^0.2.2",
    "@xenova/transformers": "^2.17.2",
    "cli-progress": "^3.12.0",
    "fs": "^0.0.1-security"
  }
}
